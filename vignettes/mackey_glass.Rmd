---
title: "Mackey Glass"
author: "Andreas M. Brandmaier"
date: "12/15/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

First, we load the shared library.

```{r load, echo=TRUE}


  dyn.load(paste("../bnnlib", .Platform$dynlib.ext, sep=""))
  source("../bnnlib.R")
  cacheMetaData(1)

```

This is the Mackey-Glass time series: 

```{r}
x <- read.csv("../datasets/mackey-glass.dat")[,1]
x <- x[seq(1,length(x),2)] # take every other
dat <- data.frame(x=1:length(x),y=x)
dat1 <- dat[1:500,]
dat2 <- dat[500:1000,]
library(ggplot2)
ggplot(data=dat, mapping = aes(x=x,y=y) )+geom_line()+
  theme_minimal()+ ggtitle("Mackey Glass Series","Observations 1 to 500")
ggplot(data=dat2, mapping = aes(x=x,y=y) )+geom_line()+ 
  theme_minimal()+ ggtitle("Mackey Glass Series","Observations 500 to 1000")

```

You can also embed plots, for example:

```{r training, echo=FALSE}

connectivity = .8 # between 0 and 1
hidden_layer_size = 10
num_backward_connections = 5*hidden_layer_size

network = NetworkFactory_create_random_gate_network(1,hidden_layer_size,1,
			connectivity,num_backward_connections);

network = LSTMNetwork(1, 10, 1);

 training_set = SequenceSet("../datasets/mackey-glass.dat");

SequenceSet_scale_to_minmax(training_set, -1,+1);

trainer = ImprovedRPropTrainer(network);
		
	Trainer_learning_rate_set( trainer, 0.0001 );

Trainer_batch_learning_set(trainer, TRUE)


#	trainer->abort_criteria.push_back( new ConvergenceCriterion(10e-7) );

#Trainer_add_abort_criterion( ConvergenceCriterion(.00001))

	Trainer_train2(trainer, training_set, 500)

#	GnuplotGenerator_plot_vector__SWIG_0("Training Error", Trainer_error_train_get(trainer))

	values <- .Call('R_swig_toValue',  Trainer_error_train_get(trainer), package="bnnlib") 
	
	library(ggplot2)
	ggplot2::ggplot(data.frame(x=1:length(values),values),aes(x=x,y=values))+geom_point()+
	  geom_line()+geom_smooth()
#	GnuplotGenerator_plot_vector__SWIG_0()
#	network->test_sequence( training_set, true );

```

Forecasting the time-series

```{r autopred}
sequence = SequenceSet_get(training_set,0)


 setClass("_p_std__vectorT_std__vectorT_double_std__allocatorT_double_t_t_p_std__allocatorT_std__vectorT_double_std__allocatorT_double_t_t_p_t_t", contains = 'ExternalReference')

#predictor = AutoPredictor__SWIG_2(network, LinearTransferFunction() )
#predictor = AutoPredictor__SWIG_2(network, LinearAddedNoiseTransferFunction(.1) )
predictor = AutoPredictor__SWIG_2(network, LinearDampenedTransferFunction(.99) )

time_steps <- 400
context <- 200
x = AutoPredictor_predict( predictor, sequence, time_steps, context)

#x = Network_activate_and_return_activations(network, sequence)
```

```{r broken}
vals <- sapply(1:time_steps, FUN = function(index){getRow(x, index-1)})
#getLength(x)
plot(vals,type="l")
#	AutoPredictor predictor2(network, new LinearTransferFunction() );
#		predictor2.predict_and_plot( sequence, sequence->size(), 1000);

```

